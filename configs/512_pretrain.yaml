exp_name: MicroDiT_XL_Masked_512_pretrain
seed: 1337
algorithms:
  ema:
    _target_: diffusion.algorithms.ema.EMA
    half_life: null
    smoothing: 0.99975
    update_interval: 1ba
    ema_start: 25000ba
  low_precision_layernorm:
    precision: amp_bf16
  gradient_clipping:
    clipping_type: norm
    clip_norm: 0.5

model:
  _target_: micro_diffusion.models.model.create_latent_diffusion
  vae_name: stabilityai/stable-diffusion-xl-base-1.0
  text_encoder_name: openclip:hf-hub:apple/DFN5B-CLIP-ViT-H-14-378
  dit_arch: MicroDiT_XL
  latents_precomputed: true
  in_channels: 4
  pos_interp_scale: 2.0
  dtype: 'bfloat16'
  latent_res: 64
  p_mean: 0
  p_std: 0.6 # to compensate for higher resolution
  train_mask_ratio: 0.75

dataset:
  image_size: 512 # 8x latent_res
  train_batch_size: 2048
  eval_batch_size: 1024
  cap_drop_prob: 0.1
  train:
    _target_: micro_diffusion.datasets.latents_loader.build_streaming_latents_dataloader
    datadir:
      - ./datadir/sa1b/sa1b_mds_latents/
      - ./datadir/jdb/jdb_mds_latents/train/
      - ./datadir/diffdb/diffdb_mds_latents/
    drop_last: true
    shuffle: true
    prefetch_factor: 2
    num_workers: 2
    persistent_workers: true
    pin_memory: true
  eval:
    _target_: micro_diffusion.datasets.latents_loader.build_streaming_latents_dataloader
    datadir:
     - ./datadir/coco/coco_mds_latents/
     - ./datadir/jdb/jdb_mds_latents/valid
    drop_last: false
    shuffle: true
    prefetch_factor: 2
    num_workers: 2
    persistent_workers: true
    pin_memory: true
optimizer:
  _target_: torch.optim.AdamW
  lr: 8e-5
  weight_decay: 0.1
  eps: 1.0e-8
  betas:
    - 0.9
    - 0.999
scheduler:
  _target_: composer.optim.ConstantWithWarmupScheduler
  t_warmup: 500ba
  alpha: 1.0
logger:
  progress:
    _target_: composer.loggers.TensorboardLogger
callbacks:
  speed_monitor:
    _target_: composer.callbacks.speed_monitor.SpeedMonitor
    window_size: 3
  lr_monitor:
    _target_: composer.callbacks.lr_monitor.LRMonitor
  runtime_estimator:
    _target_: composer.callbacks.runtime_estimator.RuntimeEstimator
  optimizer_monitor:
    _target_: composer.callbacks.OptimizerMonitor
  image_monitor:
    _target_: micro_diffusion.models.callbacks.LogDiffusionImages
    # provide a .pt file to load latent prompts directly from if openclip doesnt fit on VRAM with the model
    caption_latents_path: "./utility_clip/caption_latents.pt"
    latent_prompts: null
    prompts:
      - Ocean wave, aesthetic, soothing, turquoise blue
      - Funny portrait of a koala
      - Mysterious tree surrounded by lake
      - A heroic girl's silhouette with moon as backdrop, moon is partially covered by clouds, its evening
      - An armed hero with cape standing near explosion, warm color scheme
      - Malevolent wizard with his staff and hat
      - Watercolor splash art of a butterfly, purple yellow green blue
      - A bird on branch with moon backdrop, ominous, scary 
      - Sunset over mountains, river of blood
      - monster in ominous forest, lake, moon, night
      - volcano galaxy explosion blue purple ominous
    guidance_scale: 5
    sampling_steps: 30
    seed: ${seed}
  nan_catcher:
    _target_: micro_diffusion.models.callbacks.NaNCatcher
trainer:
  _target_: composer.Trainer
  device: gpu
  max_duration: 50000ba
  eval_interval: 2500ba
  save_interval: 2500ba
  save_num_checkpoints_to_keep: 1
  device_train_microbatch_size: 32
  run_name: ${exp_name}
  seed: ${seed}
  save_folder: ./trained_models/${exp_name}/
  load_path: path_to_final_ckpt_from_res_256_finetune_run
  load_weights_only: true
  load_strict_model_weights: false
  load_ignore_keys: ["state/model/dit.pos_embed"]
  save_overwrite: true
  autoresume: false
  fsdp_config:
    sharding_strategy: "SHARD_GRAD_OP"
misc:
  compile: true