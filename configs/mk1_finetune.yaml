exp_name: mk1_finetune
seed: 1337
algorithms:
  low_precision_layernorm:
    precision: amp_bf16
  gradient_clipping:
    clipping_type: norm
    clip_norm: 0.25

model:
  _target_: ex_micro_diffusion.models.model.create_latent_diffusion
  vae_name: stabilityai/stable-diffusion-xl-base-1.0
  text_encoder_name: null
  dit_arch: MicroDiT_Tiny
  latents_precomputed: true
  in_channels: 4
  pos_interp_scale: 1.0
  dtype: 'bfloat16'
  latent_res: 32
  p_mean: -0.6
  p_std: 1.2
  train_mask_ratio: 0.0

dataset:
  image_size: 256 # 8x latent_res
  train_batch_size: 8
  eval_batch_size: 8
  cap_drop_prob: 0.1
  train:
    _target_: ex_micro_diffusion.datasets.latents_loader.build_streaming_latents_dataloader
    datadir:
      - ./datadir/jdb/jdb_mds_latents/train/
    drop_last: true
    shuffle: true
    prefetch_factor: 2
    num_workers: 2
    persistent_workers: true
    pin_memory: true
  eval:
    _target_: ex_micro_diffusion.datasets.latents_loader.build_streaming_latents_dataloader
    datadir: 
      - ./datadir/jdb/jdb_mds_latents/valid/
    drop_last: false
    shuffle: true
    prefetch_factor: 2
    num_workers: 2
    persistent_workers: true
    pin_memory: true

optimizer:
  _target_: torch.optim.AdamW
  lr: 8e-5
  weight_decay: 0.1
  eps: 1.0e-8
  betas:
    - 0.9
    - 0.999

scheduler:
  _target_: composer.optim.ConstantScheduler
  alpha: 1.0

logger:
  progress:
    _target_: composer.loggers.TensorboardLogger

callbacks:
  speed_monitor:
    _target_: composer.callbacks.speed_monitor.SpeedMonitor
    window_size: 3
  lr_monitor:
    _target_: composer.callbacks.lr_monitor.LRMonitor
  runtime_estimator:
    _target_: composer.callbacks.runtime_estimator.RuntimeEstimator
  optimizer_monitor:
    _target_: composer.callbacks.OptimizerMonitor
  image_monitor:
    _target_: ex_micro_diffusion.models.callbacks.LogDiffusionImages
    # provide a .pt file to load latent prompts directly from if openclip doesnt fit on VRAM with the model
    caption_latents_path: "./utility_clip/caption_latents.pt"
    latent_prompts: null
    prompts:
      - Ocean wave, aesthetic, soothing, turquoise blue
      - Funny portrait of a koala
      - Mysterious tree surrounded by lake
      - A heroic girl's silhouette with moon as backdrop, moon is partially covered by clouds, its evening
      - An armed hero with cape standing near explosion, warm color scheme
      - Malevolent wizard with his staff and hat
      - Watercolor splash art of a butterfly, purple yellow green blue
      - A bird on branch with moon backdrop, ominous, scary 
      - Sunset over mountains, river of blood
      - monster in ominous forest, lake, moon, night
      - volcano galaxy explosion blue purple ominous
    guidance_scale: 5
    sampling_steps: 30
    seed: ${seed}
  nan.catcher:
    _target_: ex_micro_diffusion.models.callbacks.NaNCatcher

trainer:
  _target_: composer.Trainer
  device: gpu
  max_duration: 50ba
  eval_interval: 15ba
  save_interval: 15ba
  save_num_checkpoints_to_keep: 1
  device_train_microbatch_size: 2
  run_name: ${exp_name}
  seed: ${seed}
  save_folder: ./trained_models/${exp_name}/
  load_path: path_to_final_ckpt_from_res_256_pretrain_run
  load_ignore_keys: ["state/optimizers/AdamW/param_groups/initial_lr", "state/optimizers/AdamW/param_groups/lr", "state/schedulers/LambdaLR/base_lrs", "state/schedulers/LambdaLR/_last_lr"]
  save_overwrite: true
  autoresume: false
  fsdp_config:
    sharding_strategy: "SHARD_GRAD_OP"

misc:
  compile: false
